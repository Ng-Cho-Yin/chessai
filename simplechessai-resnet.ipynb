{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Resnet Models\nimport torch\nimport torch.nn as nn\nfrom numba import jit\n\n\nclass block(nn.Module):\n    def __init__(\n        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n    ):\n        super().__init__()\n        self.expansion = 4\n        self.conv1 = nn.Conv2d(\n            in_channels,\n            intermediate_channels,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n            bias=False,\n        )\n        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n        self.conv2 = nn.Conv2d(\n            intermediate_channels,\n            intermediate_channels,\n            kernel_size=3,\n            stride=stride,\n            padding=1,\n            bias=False,\n        )\n        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n        self.conv3 = nn.Conv2d(\n            intermediate_channels,\n            intermediate_channels * self.expansion,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n            bias=False,\n        )\n        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n        self.relu = nn.ReLU()\n        self.identity_downsample = identity_downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x.clone()\n        \n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        x = self.conv3(x)\n        x = self.bn3(x)\n\n        if self.identity_downsample is not None:\n            identity = self.identity_downsample(identity)\n\n        x += identity\n        x = self.relu(x)\n        return x\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, image_channels, num_classes):\n        super(ResNet, self).__init__()\n        self.in_channels = 64\n        self.conv1 = nn.Conv2d(\n            image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # Essentially the entire ResNet architecture are in these 4 lines below\n        self.layer1 = self._make_layer(\n            block, layers[0], intermediate_channels=64, stride=1\n        )\n        self.layer2 = self._make_layer(\n            block, layers[1], intermediate_channels=128, stride=2\n        )\n        self.layer3 = self._make_layer(\n            block, layers[2], intermediate_channels=256, stride=2\n        )\n        self.layer4 = self._make_layer(\n            block, layers[3], intermediate_channels=512, stride=2\n        )\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * 4, num_classes)\n\n        self.last = nn.Linear(512 * 4,num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        #x = x.reshape(x.shape[0], -1)\n        #x = self.fc(x)\n\n        x = x.view(-1,512 * 4)\n        x = self.last(x)\n\n        return x\n\n    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n        identity_downsample = None\n        layers = []\n\n        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n        # we need to adapt the Identity (skip connection) so it will be able to be added\n        # to the layer that's ahead\n        if stride != 1 or self.in_channels != intermediate_channels * 4:\n            identity_downsample = nn.Sequential(\n                nn.Conv2d(\n                    self.in_channels,\n                    intermediate_channels * 4,\n                    kernel_size=1,\n                    stride=stride,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(intermediate_channels * 4),\n            )\n\n        layers.append(\n            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n        )\n\n        # The expansion size is always 4 for ResNet 50,101,152\n        self.in_channels = intermediate_channels * 4\n\n        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n        # and also same amount of channels.\n        for i in range(num_residual_blocks - 1):\n            layers.append(block(self.in_channels, intermediate_channels))\n\n        return nn.Sequential(*layers)\n\n\ndef ResNet50(img_channel=3, num_classes=1000):\n    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\n\n\ndef ResNet101(img_channel=3, num_classes=1000):\n    return ResNet(block, [3, 4, 23, 3], img_channel, num_classes)\n\n\ndef ResNet152(img_channel=3, num_classes=1000):\n    return ResNet(block, [3, 8, 36, 3], img_channel, num_classes)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-09T14:39:09.499220Z","iopub.execute_input":"2023-03-09T14:39:09.499807Z","iopub.status.idle":"2023-03-09T14:39:12.234082Z","shell.execute_reply.started":"2023-03-09T14:39:09.499766Z","shell.execute_reply":"2023-03-09T14:39:12.232943Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model = ResNet50()\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:12.237579Z","iopub.execute_input":"2023-03-09T14:39:12.238617Z","iopub.status.idle":"2023-03-09T14:39:12.570119Z","shell.execute_reply.started":"2023-03-09T14:39:12.238571Z","shell.execute_reply":"2023-03-09T14:39:12.568741Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU()\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): block(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n      (identity_downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): block(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (2): block(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n  )\n  (layer2): Sequential(\n    (0): block(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n      (identity_downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): block(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (2): block(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (3): block(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n  )\n  (layer3): Sequential(\n    (0): block(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n      (identity_downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): block(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (2): block(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (3): block(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (4): block(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (5): block(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n  )\n  (layer4): Sequential(\n    (0): block(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n      (identity_downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): block(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (2): block(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n  (last): Linear(in_features=2048, out_features=1000, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"from timeit import default_timer as timer\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:12.572328Z","iopub.execute_input":"2023-03-09T14:39:12.572746Z","iopub.status.idle":"2023-03-09T14:39:12.578440Z","shell.execute_reply.started":"2023-03-09T14:39:12.572702Z","shell.execute_reply":"2023-03-09T14:39:12.577088Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from nvidia.dali.pipeline import pipeline_def\nimport nvidia.dali.types as types\nimport nvidia.dali.fn as fn\nfrom nvidia.dali.plugin.pytorch import DALIGenericIterator\nimport os\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:12.581353Z","iopub.execute_input":"2023-03-09T14:39:12.582489Z","iopub.status.idle":"2023-03-09T14:39:13.337746Z","shell.execute_reply.started":"2023-03-09T14:39:12.582446Z","shell.execute_reply":"2023-03-09T14:39:13.336673Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torch import optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom timeit import default_timer as timer","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:13.339071Z","iopub.execute_input":"2023-03-09T14:39:13.339463Z","iopub.status.idle":"2023-03-09T14:39:13.350191Z","shell.execute_reply.started":"2023-03-09T14:39:13.339422Z","shell.execute_reply":"2023-03-09T14:39:13.348942Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# @pipeline_def(num_threads=4, device_id=0)\n# def get_dali_pipeline():\n#     data = np.load(\"/kaggle/input/crazybig-dataset1e7npz/crazybig_dataset(1e7).npz\")\n#     X = data['X']\n#     Y = data['Y']\n#     return X,Y","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:13.352146Z","iopub.execute_input":"2023-03-09T14:39:13.352674Z","iopub.status.idle":"2023-03-09T14:39:13.358202Z","shell.execute_reply.started":"2023-03-09T14:39:13.352618Z","shell.execute_reply":"2023-03-09T14:39:13.356910Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# train_data = DALIGenericIterator(\n#     [get_dali_pipeline(batch_size=16)],\n#     ['X', 'Y'],\n#     reader_name='Reader'\n# )","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:13.360436Z","iopub.execute_input":"2023-03-09T14:39:13.361798Z","iopub.status.idle":"2023-03-09T14:39:13.367191Z","shell.execute_reply.started":"2023-03-09T14:39:13.361750Z","shell.execute_reply":"2023-03-09T14:39:13.365937Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torch import optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom timeit import default_timer as timer\nfrom nvidia.dali.pipeline import pipeline_def\nimport nvidia.dali.types as types\nimport nvidia.dali.fn as fn\nfrom nvidia.dali.plugin.pytorch import DALIGenericIterator\n\n\nclass ChessValueDataset(DALIGenericIterator):\n    def __init__(self):\n        data = np.load(\"/kaggle/input/crazybig-dataset1e7npz/crazybig_dataset(1e7).npz\")\n        self.X = data['X']\n        self.Y = data['Y']\n\n\n    def __len__(self):\n        return self.X.shape[0]\n\n    def __getitem__(self, idx):\n        return (self.X[idx],self.Y[idx])\n\n\n\ndef model_training(device,batch_size,epoch):\n    chess_dataset = ChessValueDataset()\n    train_loader = torch.utils.data.DataLoader(chess_dataset,batch_size=batch_size,num_workers=2,pin_memory=True,shuffle=True)\n\n    #model = Net()\n\n    model = ResNet50(img_channel=5, num_classes=1)\n\n\n    optimizer = optim.SGD(model.parameters(),lr = 0.0001, momentum=0.9)\n    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.1)\n    device = \"cuda\"\n    if device == \"cuda\":\n        model.cuda()\n    model.train()\n    loss_history = []\n    mean_loss_history = []\n    print(len(train_loader))\n    for epoch in range(epoch):\n        all_loss = 0\n        num_loss = 0\n        #print(len(train_loader))\n        tot = timer()\n        for batch in tqdm(train_loader,desc='Epoch training {}'.format(epoch),unit='batch'):\n            optimizer.zero_grad(set_to_none=True)\n            target = batch[-1]\n            target = target.unsqueeze(-1)\n            target = target.to('cuda:0', non_blocking=True)\n            data = batch[0].to('cuda:0', non_blocking=True)\n            data = data.float()\n            target = target.float()\n            \n            loss_fn = nn.MSELoss()\n            \n#             output = model(data)\n#             loss = loss_fn(output,target)\n\n            # Enables autocasting for the forward pass (model + loss)\n            with torch.cuda.amp.autocast(dtype=torch.float16):\n                output = model(data)\n                loss = loss_fn(output, target)\n            loss.backward()\n            optimizer.step()\n            \n\n            all_loss +=loss.item()\n            num_loss += 1\n            \n            \n        \n        scheduler.step()\n        tot_end = timer()\n\n        print(epoch,\":\",all_loss/num_loss,\"run time:\",tot_end - tot)\n        loss_history.append(all_loss/num_loss)\n        mean_loss_history.append(sum(loss_history)/(epoch+1))\n        #plot(loss_history, mean_loss_history)\n        torch.save(model.state_dict(),'/kaggle/working/value(resnet50-kaggle-1e7).pth')","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:13.368823Z","iopub.execute_input":"2023-03-09T14:39:13.369590Z","iopub.status.idle":"2023-03-09T14:39:13.386576Z","shell.execute_reply.started":"2023-03-09T14:39:13.369548Z","shell.execute_reply":"2023-03-09T14:39:13.385481Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# from tqdm import tqdm\n# import time\n# s = timer()\n# chess_dataset = ChessValueDataset()\n# train_loader = torch.utils.data.DataLoader(chess_dataset,batch_size=256,pin_memory=True,shuffle=True)\n# for data in tqdm(train_loader,position=0,desc='load train dataset'):\n#     pass\n# e = timer()\n# print(e-s)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:13.388381Z","iopub.execute_input":"2023-03-09T14:39:13.389001Z","iopub.status.idle":"2023-03-09T14:39:13.397654Z","shell.execute_reply.started":"2023-03-09T14:39:13.388916Z","shell.execute_reply":"2023-03-09T14:39:13.396530Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# from tqdm import tqdm\n# import time\n# s = timer()\n# chess_dataset = ChessValueDataset()\n# train_loader = torch.utils.data.DataLoader(chess_dataset,batch_size=256,pin_memory=True,shuffle=True)\n# for data in tqdm(train_loader,position=0,desc='load train dataset'):\n#     pass\n# e = timer()\n# print(e-s)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:13.401631Z","iopub.execute_input":"2023-03-09T14:39:13.402716Z","iopub.status.idle":"2023-03-09T14:39:13.407198Z","shell.execute_reply.started":"2023-03-09T14:39:13.402676Z","shell.execute_reply":"2023-03-09T14:39:13.406408Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# torch.backends.cudnn.benchmark = True\nif __name__ == '__main__':\n    model_training('cuda',256,10000)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:13.409106Z","iopub.execute_input":"2023-03-09T14:39:13.410150Z","iopub.status.idle":"2023-03-09T14:56:50.917585Z","shell.execute_reply.started":"2023-03-09T14:39:13.410106Z","shell.execute_reply":"2023-03-09T14:56:50.915606Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"39064\n","output_type":"stream"},{"name":"stderr","text":"Epoch training 0:  47%|████▋     | 18251/39064 [17:07<19:19, 17.95batch/s]Exception ignored in: <function WeakValueDictionary.__init__.<locals>.remove at 0x7f73f7ed23b0>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/weakref.py\", line 109, in remove\n    def remove(wr, selfref=ref(self), _atomic_removal=_remove_dead_weakref):\nKeyboardInterrupt\nEpoch training 0:  47%|████▋     | 18252/39064 [17:08<19:32, 17.75batch/s]","output_type":"stream"},{"name":"stdout","text":"Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_2474/2203411486.py\", line 3, in <module>\n    model_training('cuda',256,10000)\n  File \"/tmp/ipykernel_2474/576914872.py\", line 68, in model_training\n    output = model(data)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_2474/3919800004.py\", line 101, in forward\n    x = self.layer3(x)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 204, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_2474/3919800004.py\", line 48, in forward\n    x = self.bn1(x)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\", line 177, in forward\n    self.running_var if not self.training or self.track_running_stats else None,\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1253, in __getattr__\n    if '_parameters' in self.__dict__:\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n    stb = value._render_traceback_()\nAttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n    return f(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n  File \"/opt/conda/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n  File \"/opt/conda/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n    filename = getsourcefile(frame) or getfile(frame)\n  File \"/opt/conda/lib/python3.7/inspect.py\", line 696, in getsourcefile\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n  File \"/opt/conda/lib/python3.7/inspect.py\", line 739, in getmodule\n    f = getabsfile(module)\n  File \"/opt/conda/lib/python3.7/inspect.py\", line 708, in getabsfile\n    _filename = getsourcefile(object) or getfile(object)\n  File \"/opt/conda/lib/python3.7/inspect.py\", line 684, in getsourcefile\n    filename = getfile(object)\nKeyboardInterrupt\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_2474/2203411486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_2474/576914872.py\u001b[0m in \u001b[0;36mmodel_training\u001b[0;34m(device, batch_size, epoch)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_2474/3919800004.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_2474/3919800004.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2102\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"],"ename":"TypeError","evalue":"object of type 'NoneType' has no len()","output_type":"error"}]},{"cell_type":"code","source":"# import torch.nn as nn\n# from tqdm import tqdm\n# from nvidia.dali.pipeline import pipeline_def\n# import nvidia.dali.types as types\n# import nvidia.dali.fn as fn\n# from nvidia.dali.plugin.pytorch import DALIGenericIterator\n# import os\n# import numpy as np\n\n\n# @pipeline_def(num_threads=4, device_id=0)\n# def get_dali_pipeline():\n#     data = np.load(\"/kaggle/input/crazybig-dataset1e7npz/crazybig_dataset(1e7).npz\")\n#     X = data['X']\n#     Y = data['Y']\n#     return X,Y\n\n\n# print('get_data')\n# train_data = DALIGenericIterator([get_dali_pipeline(batch_size=16)],['X', 'Y'],reader_name='Reader')\n\n# print('train')\n\n# loss_fn = nn.MSELoss()\n# model = ResNet50(img_channel=5, num_classes=1)\n\n# all_loss = 0\n# num_loss = 0\n# #for data in tqdm(train_data,desc='Epoch training {}'.format(epoch),unit='batch'):\n# for i, data in enumerate(train_data):\n#     x,target = data[0]['X'], data[0]['Y']\n#     otput = model(x)\n#     loss = loss_fc(output, target)\n#     loss.backward()\n#     all_loss += loss.item()\n#     print(all_loss)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:56:50.919234Z","iopub.status.idle":"2023-03-09T14:56:50.920623Z","shell.execute_reply.started":"2023-03-09T14:56:50.920267Z","shell.execute_reply":"2023-03-09T14:56:50.920302Z"},"trusted":true},"execution_count":null,"outputs":[]}]}